@article{LEGIEN2017897,
title = "Agent-based Decision Support System for Technology Recommendation",
journal = "Procedia Computer Science",
volume = "108",
pages = "897 - 906",
year = "2017",
note = "International Conference on Computational Science, ICCS 2017, 12-14 June 2017, Zurich, Switzerland",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2017.05.034",
url = "http://www.sciencedirect.com/science/article/pii/S1877050917305513",
author = "Grzegorz Legien and Bartlomiej Sniezynski and Dorota Wilk-Kołodziejczyk and Stanisawa Kluska-Nawarecka and Edward Nawarecki and Krzysztof Jaśkowiec",
keywords = "agent-based expert system, inference, machine learning integration, logic of plausible reasoning",
abstract = "This paper presents an idea of a multi-agent decision support system. Agent-based technology allows for decentralized problem solving and creating complex decision support systems, mixing various processing techniques, such as simulation, reasoning and machine learning and allows for distributed knowledge. Our main contribution is an agent-based architecture for decision support systems which is an agent-based implementation of a labeled deductive system. Such approach allows to decompose an inference algorithm into separate modules and distribute knowledge base into parts. The system is tested on a domain of material choice support for casting."
}

@InProceedings{kozlak_2019_agenty,
author="Ko{\'{z}}lak, Jaros{\l}aw
and Sniezynski, Bartlomiej
and Wilk-Ko{\l}odziejczyk, Dorota
and Le{\'{s}}niak, Albert
and Ja{\'{s}}kowiec, Krzysztof",
editor="Rodrigues, Jo{\~a}o M. F.
and Cardoso, Pedro J. S.
and Monteiro, J{\^a}nio
and Lam, Roberto
and Krzhizhanovskaya, Valeria V.
and Lees, Michael H.
and Dongarra, Jack J.
and Sloot, Peter M.A.",
title="Multi-agent Environment for Decision-Support in Production Systems Using Machine Learning Methods",
booktitle="Computational Science -- ICCS 2019",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="517--529",
abstract="This paper presents a model and implementation of a multi-agent system to support decisions to optimize a production process in companies. Our goal is to choose the most desirable parameters of the technological process using computer simulation, which will help to avoid or reduce the number of much more expensive trial production processes, using physical production lines. These identified values of production process parameters will be applied later in a real mass production. Decision-making strategies are selected using different machine learning techniques that assist in obtaining products with the required parameters, taking into account sets of historical data. The focus was primarily on the analysis of the quality of prediction of the obtained product parameters for the different algorithms used and different sizes of historical data sets, and therefore different details of information, and secondly on the examination of the times necessary for building decision models for individual algorithms and data--sets. The following algorithms were used: Multilayer Perceptron, Bagging, RandomForest, M5P and Voting. The experiments presented were carried out using data obtained for foundry processes. The JADE platform and the Weka environment were used to implement the multi--agent system.",
isbn="978-3-030-22741-8"
}

@article{POURASIABI2012782,
title = "Development a multi-layer perceptron artificial neural network model to estimate the Vickers hardness of Mn–Ni–Cu–Mo austempered ductile iron",
journal = "Materials \& Design",
volume = "35",
pages = "782 - 789",
year = "2012",
note = "New Rubber Materials, Test Methods and Processes",
issn = "0261-3069",
doi = "https://doi.org/10.1016/j.matdes.2011.09.052",
url = "http://www.sciencedirect.com/science/article/pii/S0261306911006777",
author = "HaMiD PourAsiabi and Hamed PourAsiabi and Zhila AmirZadeh and Mohammad BabaZadeh",
keywords = "A. Ferrous metals and alloys, C. Casting, C. Heat treatments",
abstract = "The hardness of austempered ductile irons is relative to its microstructure, strength, ductility, machinability and wear resistance properties. Therefore, hardness measurement can be used as a simple tool to control the heat treatment, chemical composition and mechanical properties of ADI parts during the production process. The aim of this study is to develop an Artificial Neural Network (ANN) model for estimating the Vickers hardness of ADIs after austempering treatment. A Multi-Layer Perceptron model (MLP–ANN) was used with Mo\%, Cu\%, austempering time and temperature as inputs and the Vickers hardness of samples after austempering as the output of the model. A variety of samples were prepared in different conditions of chemical composition and heat treatment cycle. The obtained experimental results were used for training the neural network. Efficiency test of the model showed reasonably good agreement between experimental and numerical results, so the synthesized ANN model can estimate the hardness of the castings with a small error in the range of the experimental results standard deviation."
}

@InProceedings{10.1007/978-3-030-36802-9_43,
author="Savangouder, Ravindra V.
and Patra, Jagdish C.
and Bornand, C{\'e}dric",
editor="Gedeon, Tom
and Wong, Kok Wai
and Lee, Minho",
title="Artificial Neural Network-Based Modeling for Prediction of Hardness of Austempered Ductile Iron",
booktitle="Neural Information Processing",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="405--413",
abstract="Austempered ductile iron (ADI), because of its attractive properties, for example, high tensile strength along with good ductility is widely used in automotive industries. Such properties of ADI primarily depend on two factors: addition of a delicate proportion of several chemical compositions during the production of ductile cast iron and an isothermal heat treatment process, called austempering process. The chemical compositions, depending on the austempering temperature and its time duration, interact in a complex manner that influences the microstructure of ADI, and determines its hardness and ductility. Vickers hardness number (VHN) is commonly used as a measure of the hardness of a material. In this paper, an artificial neural network (ANN)-based modeling technique is proposed to predict the VHN of ADI by taking experimental data from literature. Extensive simulations showed that the ANN-based model can predict the VHN with a maximum mean absolute error (MAPE) of 0.22{\%}, considering seven chemical compositions, in contrast to 0.71{\%} reported in the recent paper considering only two chemical compositions.",
isbn="978-3-030-36802-9"
}

@InProceedings{10.1007/978-3-030-36802-9_44,
author="Savangouder, Ravindra V.
and Patra, Jagdish C.
and Bornand, C{\'e}dric",
editor="Gedeon, Tom
and Wong, Kok Wai
and Lee, Minho",
title="Prediction of Hardness of Austempered Ductile Iron Using Enhanced Multilayer Perceptron Based on Chebyshev Expansion",
booktitle="Neural Information Processing",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="414--422",
abstract="In various industries, e.g., manufacturing, railways, and automotive, austempered ductile iron (ADI), is extensively used because of its desirable characteristics for example, high tensile strength with good ductility. The hardness and ductility of ADI can be tailor-made for a specific application by following an appropriate process. Such characteristics can be achieved by (i) adding a delicate proportion of several chemical compositions during the production of ductile cast iron and then followed by (ii) an isothermal heat treatment process, called austempering process. The chemical compositions, depending on the austempering temperature and its time duration, interact in a complex manner that influences the microstructure of ADI, and determines its hardness and ductility. Vickers hardness number (VHN) is commonly used as a measure of the hardness of a material. In this paper, we propose a computationally efficient enhanced multilayer perceptron (eMLP)-based technique to model the austempering process of ADI for prediction of VHN by taking experimental data reported in literature. By comparing the performance of the eMLP model with an MLP-based model, we have shown that the proposed model provides similar performance but with less computational complexity.",
isbn="978-3-030-36802-9"
}

@article{doi:10.1080/13640461.2003.11819537,
author = {M. A. Yescas},
title = {Prediction of the Vickers hardness in austempered ductile irons using neural networks},
journal = {International Journal of Cast Metals Research},
volume = {15},
number = {5},
pages = {513-521},
year  = {2003},
publisher = {Taylor & Francis},
doi = {10.1080/13640461.2003.11819537},
URL = {https://doi.org/10.1080/13640461.2003.11819537},
eprint = {https://doi.org/10.1080/13640461.2003.11819537}
}


@ARTICLE{777072,
  author={L. {Arafeh} and H. {Singh} and S. K. {Putatunda}},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)}, 
  title={A neuro fuzzy logic approach to material processing}, 
  year={1999},
  volume={29},
  number={3},
  pages={362-370},
}

@incollection{Kochanski12,
author = {Andrzej Kochanski and Marcin Perzyk and Marta Klebczyk},
title = {Knowledge in Imperfect Data},
booktitle = {Advances in Knowledge Representation},
publisher = {IntechOpen},
address = {Rijeka},
year = {2012},
editor = {Carlos Ramírez Gutiérrez},
chapter = {8},
doi = {10.5772/37714},
url = {https://doi.org/10.5772/37714}
}

@article{doi:10.1002/srin.201100189,
author = {Kumar, Aman and Chakrabarti, Debalay and Chakraborti, Nirupam},
title = {Data-Driven Pareto Optimization for Microalloyed Steels Using Genetic Algorithms},
journal = {steel research international},
volume = {83},
number = {2},
pages = {169-174},
keywords = {steels, data-driven modeling, mechanical properties, ductility, genetic algorithms, multi-objective optimization, Pareto frontier},
doi = {10.1002/srin.201100189},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/srin.201100189},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/srin.201100189},
abstract = {Abstract A data base was put together for the mechanical properties of microalloyed steels, which contained about 800 entries for ultimate tensile strength (UTS), yield strength (YS), and elongation. Using an evolutionary neural network, based upon a predator–prey genetic algorithms of bi-objective type, this information was used to construct data-driven models for UTS, YS, and elongation. The optimum Pareto tradeoffs between these properties were obtained using a multi-objective genetic algorithm. The results led to some hitherto unexplored steel compositions with optimum properties. Some such steels were actually cast and the experimentally observed property values were found to be well in accord with the predicted results.},
year = {2012}
}

@article{YESCAS2001162,
title = "Estimation of the amount of retained austenite in austempered ductile irons using neural networks",
journal = "Materials Science and Engineering: A",
volume = "311",
number = "1",
pages = "162 - 173",
year = "2001",
issn = "0921-5093",
doi = "https://doi.org/10.1016/S0921-5093(01)00913-3",
url = "http://www.sciencedirect.com/science/article/pii/S0921509301009133",
author = "M.A Yescas and H.K.D.H Bhadeshia and D.J MacKay",
keywords = "Retained austenite, Austempered, Bainite, Ductile iron, Neural networks",
abstract = "Many of the properties of austempered ductile iron depend on the austenite which is retained following the bainite reaction. A neural network model within a Bayesian framework has been created using published data to model the retained austenite content. The model allows the quantity of retained austenite to be estimated as a function of the chemical composition and heat treatment parameters. The computer programs associated with the work have been made freely available (http //www.msm.cam.ac.uk/map/mapmain.html)"
}

@article{joshi2020,
author = {Joshi, Deepak and Putatunda, Susil},
year = {2020},
month = {01},
pages = {},
title = {A Novel Step-Up Austenitization and Austempering Heat Treatment Process for Ductile Cast Iron},
volume = {12},
journal = {Research \& Development in Material Science},
doi = {10.31031/RDMS.2020.12.000794}
}

@techreport{pnen1564,
    TITLE = "Odlewnictwo -- Żeliwo sferoidalne ausferrytyczne",
    TYPE="{PN-EN}",
    NUMBER="1564:2012",
    YEAR = {2015},
    MONTH = {September},
    DAY = {28},
    PUBLISHER = {Polski Komitet Normalizacyjny},
    INSTITUTION = {Polski Komitet Normalizacyjny},
    KEY={odlewnictwo}
}

@misc{hard_conversion,
  title = {Tabela konwersji twardości},
  author = {Kelly Pipe},
  note  =  {\url{http://www.kellypipe.com/wp-content/uploads/2018/07/hardcon.pdf}, Dostęp: 18.11.2020},
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@misc{tensorflow2015-whitepaper,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{\i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}

@inproceedings{xgboost,
 author = {Chen, Tianqi and Guestrin, Carlos},
 title = {{XGBoost}: A Scalable Tree Boosting System},
 booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 series = {KDD '16},
 year = {2016},
 isbn = {978-1-4503-4232-2},
 location = {San Francisco, California, USA},
 pages = {785--794},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2939672.2939785},
 doi = {10.1145/2939672.2939785},
 acmid = {2939785},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {large-scale machine learning},
}
@book{crossvalidation,
  title={The Collected Works of John W. Tukey: Philosophy and Principles of Data Analysis 1965-1986},
  author={Jones, Lyle V},
  volume={4},
  year={1987},
  publisher={CRC Press},
  pages = {637-641}
}
@article{random_forest,
  title={Random forests},
  author={Breiman, Leo},
  journal={Machine learning},
  volume={45},
  number={1},
  pages={5--32},
  year={2001},
  publisher={Springer}
}

@article{gradient_boosting,
 ISSN = {00905364},
 URL = {http://www.jstor.org/stable/2699986},
 abstract = {Function estimation/approximation is viewed from the perspective of numerical optimization in function space, rather than parameter space. A connection is made between stagewise additive expansions and steepest-descent minimization. A general gradient descent "boosting" paradigm is developed for additive expansions based on any fitting criterion. Specific algorithms are presented for least-squares, least absolute deviation, and Huber-M loss functions for regression, and multiclass logistic likelihood for classification. Special enhancements are derived for the particular case where the individual additive components are regression trees, and tools for interpreting such "TreeBoost" models are presented. Gradient boosting of regression trees produces competitive, highly robust, interpretable procedures for both regression and classification, especially appropriate for mining less than clean data. Connections between this approach and the boosting methods of Freund and Shapire and Friedman, Hastie and Tibshirani are discussed.},
 author = {Jerome H. Friedman},
 journal = {The Annals of Statistics},
 number = {5},
 pages = {1189--1232},
 publisher = {Institute of Mathematical Statistics},
 title = {Greedy Function Approximation: A Gradient Boosting Machine},
 volume = {29},
 year = {2001}
}

@article{ensemble_averaging,
author = {Ury Naftaly and Nathan Intrator and David Horn},
title = {Optimal ensemble averaging of neural networks},
journal = {Network: Computation in Neural Systems},
volume = {8},
number = {3},
pages = {283-296},
year  = {1997},
publisher = {Taylor & Francis},
doi = {10.1088/0954-898X\_8\_3\_004},

URL = { 
        https://doi.org/10.1088/0954-898X_8_3_004
    
},
eprint = { 
        https://doi.org/10.1088/0954-898X_8_3_004
    
}

}

@article{james,
author = {De Beukelaer, Herman and Davenport, Guy F. and De Meyer, Geert and Fack, Veerle},
title = {JAMES: An object-oriented Java framework for discrete optimization using local search metaheuristics},
journal = {Software: Practice and Experience},
volume = {47},
number = {6},
pages = {921-938},
keywords = {discrete optimization, metaheuristics, local search, framework, object-oriented, Java},
doi = {https://doi.org/10.1002/spe.2459},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.2459},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/spe.2459},
abstract = {Summary This paper describes the Java Metaheuristics Search framework (JAMES, v1.1): an object-oriented Java framework for discrete optimization using local search algorithms that exploits the generality of such metaheuristics by clearly separating search implementation and application from problem specification. A wide range of generic local searches are provided, including (stochastic) hill climbing, tabu search, variable neighbourhood search and parallel tempering. These can be applied to any user-defined problem by plugging in a custom neighbourhood for the corresponding solution type. Using an automated analysis workflow, the performance of different search algorithms can be compared in order to select an appropriate optimization strategy. Implementations of specific components are included for subset selection, such as a predefined solution type, generic problem definition and several subset neighbourhoods used to modify the set of selected items. Additional components for other types of problems (e.g. permutation problems) are provided through an extensions module which also includes the analysis workflow. In comparison with existing Java metaheuristics frameworks that mainly focus on population-based algorithms, JAMES has a much lower memory footprint and promotes efficient application of local searches by taking full advantage of move-based evaluation. Releases of JAMES are deployed to the Maven Central Repository so that the framework can easily be included as a dependency in other Java applications. The project is fully open source and hosted on GitHub. More information can be found at http://www.jamesframework.org. Copyright © 2016 John Wiley \& Sons, Ltd.},
year = {2017}
}

@inproceedings{jMetal,
author = {Nebro, Antonio J. and Durillo, Juan J. and Vergne, Matthieu},
title = {Redesigning the JMetal Multi-Objective Optimization Framework},
year = {2015},
isbn = {9781450334884},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2739482.2768462},
doi = {10.1145/2739482.2768462},
abstract = {jMetal, an open source, Java-based framework for multi-objective optimization with metaheuristics, has become a valuable tool for many researches in the area as well as for some industrial partners in the last ten years. Our experience using and maintaining it during that time, as well as the received comments and suggestions, have helped us improve the jMetal design and identify significant features to incorporate. This paper revisits the jMetal architecture, describing its refined new design, which relies on design patterns, principles from object-oriented design, and a better use of the Java language features to improve the quality of the code, without disregarding jMetal ever goals of simplicity, facility of use, flexibility, extensibility and portability. Among the newly incorporated features, jMetal supports live interaction with running algorithms and parallel execution of algorithms.},
booktitle = {Proceedings of the Companion Publication of the 2015 Annual Conference on Genetic and Evolutionary Computation},
pages = {1093–1100},
numpages = {8},
keywords = {jmetal, optimization framework, multi-objective metaheu- ristics, open source},
location = {Madrid, Spain},
series = {GECCO Companion '15}
}

@Book{hillclimbing,
  title={Artificial Intelligence: A Modern Approach},
  author={Russell, Stuart J and Norvig, Peter},
  year={2016},
  publisher={Pearson Education Limited},
  pages = {122-124}
}

@article{tabusearch,
  title={Tabu Search: A Tutorial},
  author={F. Glover},
  journal={Interfaces},
  year={1990},
  volume={20},
  pages={74-94}
}

@ARTICLE{metropolis,
  author={I. {Beichl} and F. {Sullivan}},
  journal={Computing in Science   Engineering}, 
  title={The Metropolis Algorithm}, 
  year={2000},
  volume={2},
  number={1},
  pages={65-69},
  doi={10.1109/5992.814660}}

@article{paralleltempering,
    author = {Sambridge, Malcolm},
    title = "{A Parallel Tempering algorithm for probabilistic sampling and multimodal optimization}",
    journal = {Geophysical Journal International},
    volume = {196},
    number = {1},
    pages = {357-374},
    year = {2013},
    month = {10},
    abstract = "{Non-linear inverse problems in the geosciences often involve probabilistic sampling of multimodal density functions or global optimization and sometimes both. Efficient algorithmic tools for carrying out sampling or optimization in challenging cases are of major interest. Here results are presented of some numerical experiments with a technique, known as Parallel Tempering, which originated in the field of computational statistics but is finding increasing numbers of applications in fields ranging from Chemical Physics to Astronomy. To date, experience in use of Parallel Tempering within earth sciences problems is very limited. In this paper, we describe Parallel Tempering and compare it to related methods of Simulated Annealing and Simulated Tempering for optimization and sampling, respectively. A key feature of Parallel Tempering is that it satisfies the detailed balance condition required for convergence of Markov chain Monte Carlo (McMC) algorithms while improving the efficiency of probabilistic sampling. Numerical results are presented on use of Parallel Tempering for trans-dimensional inversion of synthetic seismic receiver functions and also the simultaneous fitting of multiple receiver functions using global optimization. These suggest that its use can significantly accelerate sampling algorithms and improve exploration of parameter space in optimization. Parallel Tempering is a meta-algorithm which may be used together with many existing McMC sampling and direct search optimization techniques. It's generality and demonstrated performance suggests that there is significant potential for applications to both sampling and optimization problems in the geosciences.}",
    issn = {0956-540X},
    doi = {10.1093/gji/ggt342},
    url = {https://doi.org/10.1093/gji/ggt342},
    eprint = {https://academic.oup.com/gji/article-pdf/196/1/357/5963798/ggt342.pdf},
}
@InProceedings{nsgaii,
author="Deb, Kalyanmoy
and Agrawal, Samir
and Pratap, Amrit
and Meyarivan, T.",
editor="Schoenauer, Marc
and Deb, Kalyanmoy
and Rudolph, G{\"u}nther
and Yao, Xin
and Lutton, Evelyne
and Merelo, Juan Julian
and Schwefel, Hans-Paul",
title="A Fast Elitist Non-dominated Sorting Genetic Algorithm for Multi-objective Optimization: NSGA-II",
booktitle="Parallel Problem Solving from Nature PPSN VI",
year="2000",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="849--858",
abstract="Multi-objective evolutionary algorithms which use non-dominated sorting and sharing have been mainly criticized for their (i) O(MN3) computational complexity (where M is the number of objectives and N is the population size), (ii) non-elitism approach, and (iii) the need for specifying a sharing parameter. In this paper, we suggest a non-dominated sorting based multi-objective evolutionary algorithm (we called it the Non-dominated Sorting GA-II or NSGA-II) which alleviates all the above three difficulties. Specifically, a fast non-dominated sorting approach with O(MN2) computational complexity is presented. Second, a selection operator is presented which creates a mating pool by combining the parent and child populations and selecting the best (with respect to fitness and spread) N solutions. Simulation results on five difficult test problems show that the proposed NSGA-II, in most problems, is able to find much better spread of solutions and better convergence near the true Pareto-optimal front compared to PAES and SPEA---two other elitist multi-objective EAs which pay special attention towards creating a diverse Pareto-optimal front. Because of NSGA-II's low computational requirements, elitist approach, and parameter-less sharing approach, NSGA-II should find increasing applications in the years to come.",
isbn="978-3-540-45356-7"
}

@book{negnevitsky2005artificial,
  title={Artificial intelligence: a guide to intelligent systems},
  author={Negnevitsky, Michael},
  year={2005},
  publisher={Pearson education},
  pages={175--176}
}

@article{radivsa2017casting,
  title={Casting improvement based on metaheuristic optimization and numerical simulation},
  author={Radi{\v{s}}a, Radomir and Du{\v{c}}i{\'c}, Nedeljko and Manasijevi{\'c}, Sre{\'c}ko and Markovi{\'c}, Nemanja and {\'C}ojba{\v{s}}i{\'c}, {\v{Z}}arko},
  journal={Facta Universitatis, Series: Mechanical Engineering},
  volume={15},
  number={3},
  pages={397--411},
  year={2017}
}

@article{bagging,
  title={Bagging predictors},
  author={Breiman, Leo},
  journal={Machine learning},
  volume={24},
  number={2},
  pages={123--140},
  year={1996},
  publisher={Springer}
}

@inproceedings{adaboost,
  title={Experiments with a new boosting algorithm},
  author={Freund, Yoav and Schapire, Robert E and others},
  booktitle={icml},
  volume={96},
  pages={148--156},
  year={1996},
  organization={Citeseer}
}

@article{Wilk-Kolodziejczyk2018,
  title={The Selection of heat treatment parameters to obtain austempered ductile iron with the required impact strength},
  author={Wilk-Ko{\l}odziejczyk, Dorota and Regulski, Krzysztof and Gi{\k{e}}tka, Tomasz and Gumienny, Grzegorz and Ja{\'s}kowiec, Krzysztof and Kluska-Nawarecka, Stanis{\l}awa},
  journal={Journal of Materials Engineering and Performance},
  volume={27},
  number={11},
  pages={5865--5878},
  year={2018},
  publisher={Springer}
}



